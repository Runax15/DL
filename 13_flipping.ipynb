{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Step 1: Load and Preprocess Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = np.expand_dims(x_train, -1) / 255.0, np.expand_dims(x_test, -1) / 255.0  # Normalize and expand dims\n",
    "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)  # One-hot encode labels\n",
    "\n",
    "# Step 2: Define CNN Model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')  # Output layer for 10 classes\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 3: Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random width shift\n",
    "    height_shift_range=0.2,  # Random height shift\n",
    "    shear_range=0.2,  # Shearing transformation\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True,  # Horizontal flip\n",
    "    fill_mode='nearest'  # Filling the newly created pixels\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Step 4: Train Model with Augmented Data\n",
    "model_aug = create_model()\n",
    "history_aug = model_aug.fit(datagen.flow(x_train, y_train, batch_size=64), epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Step 5: Train Model on Original Data (Without Augmentation)\n",
    "model_no_aug = create_model()\n",
    "history_no_aug = model_no_aug.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "# Step 6: Plot Training and Validation Accuracy for Both Models\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_aug.history['accuracy'], label='Train Accuracy (Augmented)')\n",
    "plt.plot(history_aug.history['val_accuracy'], label='Validation Accuracy (Augmented)')\n",
    "plt.title('CNN with Data Augmentation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_no_aug.history['accuracy'], label='Train Accuracy (Original)')\n",
    "plt.plot(history_no_aug.history['val_accuracy'], label='Validation Accuracy (Original)')\n",
    "plt.title('CNN without Data Augmentation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
